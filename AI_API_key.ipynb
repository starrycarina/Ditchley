{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPY2TYXdCxQkIAQoGS8e8xu",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/starrycarina/Ditchley/blob/main/AI_API_key.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yH9QkDIK9nzb",
        "outputId": "25ba74c3-f1cf-4880-fb70-66709fffe0c3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: google-generativeai in /usr/local/lib/python3.11/dist-packages (0.8.5)\n",
            "Requirement already satisfied: google-ai-generativelanguage==0.6.15 in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (0.6.15)\n",
            "Requirement already satisfied: google-api-core in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (2.25.1)\n",
            "Requirement already satisfied: google-api-python-client in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (2.177.0)\n",
            "Requirement already satisfied: google-auth>=2.15.0 in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (2.38.0)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (5.29.5)\n",
            "Requirement already satisfied: pydantic in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (2.11.7)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (4.14.1)\n",
            "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in /usr/local/lib/python3.11/dist-packages (from google-ai-generativelanguage==0.6.15->google-generativeai) (1.26.1)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.0,>=1.56.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core->google-generativeai) (1.70.0)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.18.0 in /usr/local/lib/python3.11/dist-packages (from google-api-core->google-generativeai) (2.32.3)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from google-auth>=2.15.0->google-generativeai) (5.5.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from google-auth>=2.15.0->google-generativeai) (0.4.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.11/dist-packages (from google-auth>=2.15.0->google-generativeai) (4.9.1)\n",
            "Requirement already satisfied: httplib2<1.0.0,>=0.19.0 in /usr/local/lib/python3.11/dist-packages (from google-api-python-client->google-generativeai) (0.22.0)\n",
            "Requirement already satisfied: google-auth-httplib2<1.0.0,>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from google-api-python-client->google-generativeai) (0.2.0)\n",
            "Requirement already satisfied: uritemplate<5,>=3.0.1 in /usr/local/lib/python3.11/dist-packages (from google-api-python-client->google-generativeai) (4.2.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic->google-generativeai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic->google-generativeai) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic->google-generativeai) (0.4.1)\n",
            "Requirement already satisfied: grpcio<2.0.0,>=1.33.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.15->google-generativeai) (1.73.1)\n",
            "Requirement already satisfied: grpcio-status<2.0.0,>=1.33.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.15->google-generativeai) (1.71.2)\n",
            "Requirement already satisfied: pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 in /usr/local/lib/python3.11/dist-packages (from httplib2<1.0.0,>=0.19.0->google-api-python-client->google-generativeai) (3.2.3)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.11/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=2.15.0->google-generativeai) (0.6.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.18.0->google-api-core->google-generativeai) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.18.0->google-api-core->google-generativeai) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.18.0->google-api-core->google-generativeai) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.18.0->google-api-core->google-generativeai) (2025.7.14)\n"
          ]
        }
      ],
      "source": [
        "!pip install -U google-generativeai"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import google.generativeai as genai"
      ],
      "metadata": {
        "id": "mlLClF_L_yhq"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "os.environ['GOOGLE_API_KEY'] = 'AIzaSyAps7qsoIvaPIabC5-AvvpatzXaIGCEBFM'\n",
        "genai.configure(api_key=os.environ['GOOGLE_API_KEY'])"
      ],
      "metadata": {
        "id": "JoywsmSeAPwS"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "models = genai.list_models()\n",
        "for model in models:\n",
        "    print(f\"{model.name} — {model.supported_generation_methods}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "gttYcXS2B5C2",
        "outputId": "12858b7d-5ba1-4ef0-c6d2-1d617ff296cc"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "models/embedding-gecko-001 — ['embedText', 'countTextTokens']\n",
            "models/gemini-1.0-pro-vision-latest — ['generateContent', 'countTokens']\n",
            "models/gemini-pro-vision — ['generateContent', 'countTokens']\n",
            "models/gemini-1.5-pro-latest — ['generateContent', 'countTokens']\n",
            "models/gemini-1.5-pro-002 — ['generateContent', 'countTokens', 'createCachedContent']\n",
            "models/gemini-1.5-pro — ['generateContent', 'countTokens']\n",
            "models/gemini-1.5-flash-latest — ['generateContent', 'countTokens']\n",
            "models/gemini-1.5-flash — ['generateContent', 'countTokens']\n",
            "models/gemini-1.5-flash-002 — ['generateContent', 'countTokens', 'createCachedContent']\n",
            "models/gemini-1.5-flash-8b — ['createCachedContent', 'generateContent', 'countTokens']\n",
            "models/gemini-1.5-flash-8b-001 — ['createCachedContent', 'generateContent', 'countTokens']\n",
            "models/gemini-1.5-flash-8b-latest — ['createCachedContent', 'generateContent', 'countTokens']\n",
            "models/gemini-2.5-pro-preview-03-25 — ['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent']\n",
            "models/gemini-2.5-flash-preview-05-20 — ['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent']\n",
            "models/gemini-2.5-flash — ['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent']\n",
            "models/gemini-2.5-flash-lite-preview-06-17 — ['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent']\n",
            "models/gemini-2.5-pro-preview-05-06 — ['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent']\n",
            "models/gemini-2.5-pro-preview-06-05 — ['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent']\n",
            "models/gemini-2.5-pro — ['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent']\n",
            "models/gemini-2.0-flash-exp — ['generateContent', 'countTokens', 'bidiGenerateContent']\n",
            "models/gemini-2.0-flash — ['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent']\n",
            "models/gemini-2.0-flash-001 — ['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent']\n",
            "models/gemini-2.0-flash-lite-001 — ['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent']\n",
            "models/gemini-2.0-flash-lite — ['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent']\n",
            "models/gemini-2.0-flash-lite-preview-02-05 — ['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent']\n",
            "models/gemini-2.0-flash-lite-preview — ['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent']\n",
            "models/gemini-2.0-pro-exp — ['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent']\n",
            "models/gemini-2.0-pro-exp-02-05 — ['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent']\n",
            "models/gemini-exp-1206 — ['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent']\n",
            "models/gemini-2.0-flash-thinking-exp-01-21 — ['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent']\n",
            "models/gemini-2.0-flash-thinking-exp — ['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent']\n",
            "models/gemini-2.0-flash-thinking-exp-1219 — ['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent']\n",
            "models/gemini-2.5-flash-preview-tts — ['countTokens', 'generateContent']\n",
            "models/gemini-2.5-pro-preview-tts — ['countTokens', 'generateContent']\n",
            "models/learnlm-2.0-flash-experimental — ['generateContent', 'countTokens']\n",
            "models/gemma-3-1b-it — ['generateContent', 'countTokens']\n",
            "models/gemma-3-4b-it — ['generateContent', 'countTokens']\n",
            "models/gemma-3-12b-it — ['generateContent', 'countTokens']\n",
            "models/gemma-3-27b-it — ['generateContent', 'countTokens']\n",
            "models/gemma-3n-e4b-it — ['generateContent', 'countTokens']\n",
            "models/gemma-3n-e2b-it — ['generateContent', 'countTokens']\n",
            "models/gemini-2.5-flash-lite — ['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent']\n",
            "models/embedding-001 — ['embedContent']\n",
            "models/text-embedding-004 — ['embedContent']\n",
            "models/gemini-embedding-exp-03-07 — ['embedContent', 'countTextTokens', 'countTokens']\n",
            "models/gemini-embedding-exp — ['embedContent', 'countTextTokens', 'countTokens']\n",
            "models/gemini-embedding-001 — ['embedContent', 'countTextTokens', 'countTokens']\n",
            "models/aqa — ['generateAnswer']\n",
            "models/imagen-3.0-generate-002 — ['predict']\n",
            "models/imagen-4.0-generate-preview-06-06 — ['predict']\n",
            "models/imagen-4.0-ultra-generate-preview-06-06 — ['predict']\n",
            "models/veo-2.0-generate-001 — ['predictLongRunning']\n",
            "models/veo-3.0-generate-preview — ['predictLongRunning']\n",
            "models/gemini-2.5-flash-preview-native-audio-dialog — ['countTokens', 'bidiGenerateContent']\n",
            "models/gemini-2.5-flash-exp-native-audio-thinking-dialog — ['countTokens', 'bidiGenerateContent']\n",
            "models/gemini-2.0-flash-live-001 — ['bidiGenerateContent', 'countTokens']\n",
            "models/gemini-live-2.5-flash-preview — ['bidiGenerateContent', 'countTokens']\n",
            "models/gemini-2.5-flash-live-preview — ['bidiGenerateContent', 'countTokens']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = genai.GenerativeModel(\"models/gemini-1.5-flash\")"
      ],
      "metadata": {
        "id": "ZeT1Sb27AooX"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "testresponse = model.generate_content(\"Summarise the sentence: 'The cat sat on the mat while the dog barked at the moon.'\")\n",
        "print(testresponse.text)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "id": "3a4YeT-LAws8",
        "outputId": "5a60f3bd-0c2b-4209-81b2-9f60004c7290"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "A cat sat on a mat while a dog barked at the moon.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "usage = testresponse.usage_metadata\n",
        "\n",
        "print(f\"Prompt tokens: {usage.prompt_token_count}\")\n",
        "print(f\"Response tokens: {usage.candidates_token_count}\")\n",
        "print(f\"Total tokens: {usage.total_token_count}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AXn-J2LXCayZ",
        "outputId": "04f18863-2f05-4497-eb9c-7e7fde2acde7"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prompt tokens: 21\n",
            "Response tokens: 15\n",
            "Total tokens: 36\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install neo4j"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CmSBcN7nDkl0",
        "outputId": "0daccf93-49e8-456f-f620-9bacadaa541b"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: neo4j in /usr/local/lib/python3.11/dist-packages (5.28.1)\n",
            "Requirement already satisfied: pytz in /usr/local/lib/python3.11/dist-packages (from neo4j) (2025.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from neo4j import GraphDatabase\n",
        "import openai\n",
        "\n",
        "uri = \"neo4j+s://e22e7657.databases.neo4j.io:7687\"\n",
        "user = \"carina_clewley\"\n",
        "password = \"Nomrbox1\"\n",
        "\n",
        "driver = GraphDatabase.driver(uri, auth=(user, password))"
      ],
      "metadata": {
        "id": "bEb3ypgTDyUc"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "system_prompt = (\n",
        "    \"You are a researcher whose task is to assign organisations into one of multiple sector classifications. \"\n",
        "    \"I have outlined the ontology below. When I supply you with the name of an organisation, could you please tell me which \"\n",
        "    \"of the below sectors is the best fit. Please respond with exactly one sector name, matching one of the following options, or 'Other' if none fit:\\n\\n\"\n",
        "    \"Academia\\n\"\n",
        "    \"Arts/culture\\n\"\n",
        "    \"Finance\\n\"\n",
        "    \"IGO/multilateral\\n\"\n",
        "    \"Media/journalism\\n\"\n",
        "    \"Military/defense\\n\"\n",
        "    \"NGO/nonprofit\\n\"\n",
        "    \"Politics\\n\"\n",
        "    \"Public Service\\n\"\n",
        "    \"Technology\\n\"\n",
        "    \"Other\\n\\n\"\n",
        "    \"Here is the ontology:\\n\"\n",
        "    \"Academia: This encompasses institutions dedicated to advancing knowledge and learning. It includes organizations that conduct research, provide education, and foster intellectual growth. Examples: Harvard University, Oxford University, the Max Planck Society, the National Science Foundation.\\n\\n\"\n",
        "    \"Arts/culture: This category covers a wide range of organizations that contribute to the artistic and cultural landscape. It includes those involved in the creation, exhibition, performance, preservation, and promotion of artistic and cultural works. Examples: The Louvre Museum, the Metropolitan Opera, the Royal Shakespeare Company, the British Film Institute.\\n\\n\"\n",
        "    \"Finance: This sector encompasses firms engaged in financial activities that drive the global economy. It includes banking, investment, insurance, asset management, and accounting, as well as global management consulting practices that advise businesses on financial and strategic matters. Examples: JPMorgan Chase, Berkshire Hathaway, AIG, PwC, Boston Consulting Group.\\n\\n\"\n",
        "    \"IGO/multilateral: This category includes intergovernmental organizations and multilateral institutions that operate on a global scale to address international issues and promote cooperation among nations. Examples: The United Nations, the World Trade Organization, the North Atlantic Treaty Organization, the European Union, Embassies and Consulates.\\n\\n\"\n",
        "    \"Media/journalism: This sector comprises entities that play a crucial role in informing the public. It includes organizations that produce and distribute news, information, and entertainment across various media platforms. Examples: The New York Times, BBC, CNN, Reuters, The Guardian.\\n\\n\"\n",
        "    \"Military/defense: This category encompasses organizations responsible for national defense and security. It includes the armed forces, defense contractors, and intelligence agencies that protect national interests and maintain security. Examples: The United States Department of Defense, BAE Systems, Lockheed Martin, the Central Intelligence Agency.\\n\\n\"\n",
        "    \"NGO/nonprofit: This sector includes non-governmental organizations that operate independently of governments to address social, environmental, or humanitarian causes. They often rely on donations and volunteers to carry out their missions. Examples: Doctors Without Borders, Oxfam, the World Wildlife Fund, Human Rights Watch.\\n\\n\"\n",
        "    \"Politics: This category is specifically for individuals or groups directly involved in political activity. This includes holding elected office, working for a political party, or campaigning for political causes. Examples: Members of Parliament, the Democratic Party, the Conservative Party, political action committees.\\n\\n\"\n",
        "    \"Public Service: This sector encompasses government departments and agencies that provide essential public services to citizens. It includes organizations responsible for healthcare, education, infrastructure, social welfare, and other public goods, excluding political roles. Examples: The National Health Service (NHS), the Department of Education, the Environmental Protection Agency, public libraries, fire departments.\\n\\n\"\n",
        "    \"Technology: This sector includes companies at the forefront of technological innovation. It encompasses those involved in the development, production, and distribution of technology products and services, including software, hardware, and biotechnology. Examples: Apple, Google, Microsoft, Amazon, Tesla, Pfizer.\"\n",
        ")\n"
      ],
      "metadata": {
        "id": "tKNdbZbtD4lG"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_ai_industry(org_name, contacts_text):\n",
        "    prompt = f\"\"\"\n",
        "{system_prompt}\n",
        "\n",
        "Organisation name: {org_name}\n",
        "\n",
        "Contacts info and themes:\n",
        "{contacts_text}\n",
        "\n",
        "Please reply with only one sector from the ontology exactly as named above, or 'Other' if none apply.\n",
        "\"\"\"\n",
        "\n",
        "    response = model.generate_content(prompt)\n",
        "    return response.text.strip()"
      ],
      "metadata": {
        "id": "Ki0BR8IWEBM4"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with driver.session() as session:\n",
        "    result = session.run(\"\"\"\n",
        "        MATCH (o:Organisation)\n",
        "        OPTIONAL MATCH (o)-[:HAS_INDUSTRY]->(i:Industry)\n",
        "        WITH o, count(i) AS industry_count\n",
        "        RETURN o, elementId(o) AS eid, industry_count\n",
        "        LIMIT 20\n",
        "    \"\"\")\n",
        "\n",
        "    for record in result:\n",
        "        org_node = record[\"o\"]\n",
        "        org_eid = record[\"eid\"]\n",
        "        has_industry = record[\"industry_count\"] > 0\n",
        "\n",
        "        org_name = org_node.get(\"name\") or f\"Organisation {org_eid}\"\n",
        "\n",
        "        if has_industry:\n",
        "            session.run(\"\"\"\n",
        "                MATCH (o:Organisation)\n",
        "                WHERE elementId(o) = $org_eid\n",
        "                SET o.ai_industry = \"Already Assigned\"\n",
        "            \"\"\", org_eid=org_eid)\n",
        "            print(f\"{org_name}: Already Assigned\")\n",
        "            continue\n",
        "\n",
        "        # Collect contact info\n",
        "        contacts_result = session.run(\"\"\"\n",
        "            MATCH (o:Organisation)<-[:ASSOCIATED_WITH]-(c:Contact)\n",
        "            WHERE elementId(o) = $org_eid\n",
        "            OPTIONAL MATCH (c)-[:HAS_THEME]->(t)\n",
        "            OPTIONAL MATCH (c)-[:HAS_SUBTHEME]->(s)\n",
        "            RETURN collect(DISTINCT c.biography) AS bios,\n",
        "                   collect(DISTINCT t.name) AS themes,\n",
        "                   collect(DISTINCT s.name) AS subthemes\n",
        "        \"\"\", org_eid=org_eid)\n",
        "\n",
        "        rec = contacts_result.single()\n",
        "        bios = rec[\"bios\"] or []\n",
        "        themes = rec[\"themes\"] or []\n",
        "        subthemes = rec[\"subthemes\"] or []\n",
        "\n",
        "        contacts_info_text = \"\\n\".join(bios + themes + subthemes)\n",
        "\n",
        "        # Call Gemini to get predicted industry\n",
        "        try:\n",
        "            ai_industry_label = generate_ai_industry(org_name, contacts_info_text)\n",
        "        except Exception as e:\n",
        "            print(f\"Error processing {org_name}: {e}\")\n",
        "            continue\n",
        "\n",
        "        # Save the label back to Neo4j\n",
        "        session.run(\"\"\"\n",
        "            MATCH (o:Organisation)\n",
        "            WHERE elementId(o) = $org_eid\n",
        "            SET o.ai_industry = $ai_industry_label\n",
        "        \"\"\", org_eid=org_eid, ai_industry_label=ai_industry_label)\n",
        "\n",
        "        print(f\"{org_name}: Predicted AI Industry -> {ai_industry_label}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 384
        },
        "id": "gsgLFjiEE5MV",
        "outputId": "c1d485be-f5be-4f95-e8c0-0c6b836f0f7c"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Business: Already Assigned\n",
            "The Ditchley Foundation: Already Assigned\n",
            "Foreign, Commonwealth and Development Office (NOT IN USE): Already Assigned\n",
            "Dow Jones: Predicted AI Industry -> Finance\n",
            "University of Alberta: Already Assigned\n",
            "King's College London: Already Assigned\n",
            "University of Oxford: Already Assigned\n",
            "The London School of Economics and Political Science: Already Assigned\n",
            "University of Cambridge: Already Assigned\n",
            "University College London: Already Assigned\n",
            "University of Warwick: Already Assigned\n",
            "Chatham House: Already Assigned\n",
            "RAND Europe: Already Assigned\n",
            "St Antony's College, University of Oxford: Predicted AI Industry -> Academia\n",
            "Queen Mary, University of London: Predicted AI Industry -> Academia\n",
            "University of Nottingham: Already Assigned\n",
            "The University of Exeter: Predicted AI Industry -> Academia\n",
            "Durham University: Already Assigned\n",
            "University of Leeds: Predicted AI Industry -> Academia\n",
            "Newcastle University: Predicted AI Industry -> Academia\n"
          ]
        }
      ]
    }
  ]
}